{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# Import the plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.layers import GRU, Embedding, LSTM\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas_datareader\n",
    "from pandas_datareader import data as wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(yf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Stock Market Data using Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data of the stock AAPL\n",
    "aapl = yf.download('BTC-USD','2015-01-01','2021-03-05')\n",
    "# Plot the close price of the AAPL\n",
    "aapl['Adj Close'].plot()\n",
    "plt.title(\"Adjusted Close Price\", fontsize=16)\n",
    "# Define the labels for x-axis and y-axis\n",
    "plt.ylabel('Price', fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_daily_returns = (aapl['Adj Close'].pct_change()+1).cumprod()\n",
    "aapl_daily_returns.plot()\n",
    "plt.title(\"Adjusted Close Price\", fontsize=16)\n",
    "# Define the labels for x-axis and y-axis\n",
    "plt.ylabel('Price', fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.show()\n",
    "#aapl_monthly_returns = aapl['Adj Close'].resample('M').ffill().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_daily_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice tutorial on financial data analysis: https://www.codingfinance.com/post/2018-04-03-calc-returns-py/\n",
    "\n",
    "### Calculating the daily and monthly returns for individual stock:\n",
    "\n",
    "Once we downloaded the stock prices from yahoo finance, the next thing to do is to calculate the returns. We will again use pandas package to do the calculations. We have already downloaded the price data for AAPL above, if you havenâ€™t done that then see the above section. We will calculate the monthly and daily price returns.\n",
    "```python\n",
    "aapl_daily_returns = aapl['Adj Close'].pct_change()\n",
    "aapl_monthly_returns = aapl['Adj Close'].resample('M').ffill().pct_change()\n",
    "```\n",
    "\n",
    "### Calculating the cumulative returns for individual stock:\n",
    "\n",
    "Plotting the daily and monthly returns are useful for understanding the daily and monthly volatility of the investment. To calculate the growth of our investment or, in other words, calculating the total returns from our investment, we need to calculate the cumulative returns from that investment. To calculate the cumulative returns we will use the cumprod() function.\n",
    "```python\n",
    "aapl_cum_returns = (aapl_daily_returns + 1).cumprod()\n",
    "```\n",
    "\n",
    "#### Plot the data:\n",
    "```python\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax1.plot(aapl_cum_returns)\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Percent\")\n",
    "ax1.set_title(\"AAPL daily returns data\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Several Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ticker list\n",
    "tickers_list = ['AAPL', 'WMT','TSLA', 'IBM', 'MU', 'BA', 'AXP','GOOG','MSFT']\n",
    "\n",
    "stock_data = pd.DataFrame(columns=tickers_list)\n",
    "# Fetch the data\n",
    "\n",
    "for ticker in tickers_list:\n",
    "    stock_data[ticker] = yf.download(ticker, '2019-1-1', '2020-12-22')['Adj Close']\n",
    "# Print first 5 rows of the data\n",
    "#stock_data.head()\n",
    "\n",
    "\n",
    "# Plot all the close prices\n",
    "# the cumulative returns for individual stocks\n",
    "((stock_data.pct_change()+1).cumprod()).plot(figsize=(10, 7), linewidth=2.5)\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "# Define the label for the title of the figure\n",
    "plt.title(\"Adjusted Close Price\", fontsize=16)\n",
    "# Define the labels for x-axis and y-axis\n",
    "plt.ylabel('Return', fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "# Plot the grid lines\n",
    "plt.grid(which=\"major\", color='k', linestyle='-.', linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('foo.png', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Stock Market Data using Pandas DataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datetime as dt\n",
    "\n",
    "start = '2019-6-20'\n",
    "end = '2019-7-20'\n",
    "\n",
    "tickers = ['CSCO','AXP','HD','PG']\n",
    "\n",
    "thelen = len(tickers)\n",
    "\n",
    "price_data = []\n",
    "for ticker in tickers:\n",
    "    prices = wb.DataReader(ticker, start = start, end = end, data_source='yahoo')[['Adj Close']]\n",
    "    price_data.append(prices.assign(ticker=ticker)[['ticker', 'Adj Close']])\n",
    "\n",
    "stock_df = pd.concat(price_data)\n",
    "#stock_df.dtypes\n",
    "#stock_df.head()\n",
    "#stock_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table to summarise data\n",
    "stock_df = stock_df.reset_index()\n",
    "stock_df = stock_df.set_index('Date')\n",
    "table = stock_df.pivot(columns='ticker')\n",
    "# By specifying col[1] in below list comprehension\n",
    "# You can select the stock names under multi-level column\n",
    "table.columns = [col[1] for col in table.columns]\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in table.columns:\n",
    "    f = table[column] \n",
    "    #f = ((f.pct_change()+1).cumprod())\n",
    "    f.plot(label=column);\n",
    "    plt.legend()\n",
    "    plt.ylabel('price in [USD]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the close prices\n",
    "# the cumulative returns for individual stocks\n",
    "((table.pct_change()+1).cumprod()).plot(figsize=(10, 7))\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "# Define the label for the title of the figure\n",
    "plt.title(\"Adjusted Close Price\", fontsize=16)\n",
    "# Define the labels for x-axis and y-axis\n",
    "plt.ylabel('Price', fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "# Plot the grid lines\n",
    "plt.grid(which=\"major\", color='k', linestyle='-.', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Train/test subsets .. ONLY use IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stock_data['IBM']\n",
    "data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[:400]#aapl['Adj Close'][:250]#df['Water Level (m)'][0:100]\n",
    "print('train shape:', train_df.shape)\n",
    "test_df = data[400:]#aapl['Adj Close'][250:]#df['Water Level (m)'][100:]\n",
    "print('test shape: ',test_df.shape)\n",
    "\n",
    "print(\"Min x:\", np.min(train_df))\n",
    "print(\"Max x:\", np.max(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the Data into values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After this step train and test will become numpy matrices instead of pandas dataframes\n",
    "## NOTICE: we use the model that is fitted to the train data to scale the test data .. \n",
    "## very important to do it this way!\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "train = x_scaler.fit_transform(train_df.values.reshape(-1, 1))\n",
    "test = x_scaler.transform(test_df.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure values are between 0-1\n",
    "print(\"Min x:\", np.min(train))\n",
    "print(\"Max x:\", np.max(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Split Data into Sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create sequences for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [1,2,3,4,5,6,7,8,9,10]\n",
    "steps = 3\n",
    "split_sequence(seq,steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "# choose a number of time steps\n",
    "n_steps = 5\n",
    "# split into samples\n",
    "X_train, y_train = split_sequence(train, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create sequences for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test sequence\n",
    "# choose a number of time steps .. same as training!\n",
    "#n_steps = 5\n",
    "# split into samples\n",
    "X_test, y_test = split_sequence(test, n_steps)\n",
    "#X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Shape suitable for feeding into TF/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Fitting (RNN, LSTM and GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "\n",
    "# Single layer GRU\n",
    "#model.add(GRU(32 , input_shape=(n_steps, n_features) ))\n",
    "\n",
    "# Stacked GRU\n",
    "#model.add(GRU(8 , input_shape=(n_steps, n_features) , return_sequences=True))\n",
    "#model.add(GRU(16, return_sequences=True))\n",
    "#model.add(GRU(32))\n",
    "\n",
    "# Stacked LSTM\n",
    "model.add(LSTM(8, activation='relu', input_shape=(n_steps, n_features), return_sequences=True))\n",
    "model.add(LSTM(16, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32, verbose=1, callbacks=[es, mc])\n",
    "\n",
    "# fit model\n",
    "#model.fit(X_train, y_train, epochs=50, verbose=1, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualise performance (training loss vs validation loss)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Fitting CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "# define model\n",
    "model = Sequential()\n",
    "#model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X_train, y_train, epochs=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# load the saved model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute RMSE for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "        return np.sqrt(np.mean(np.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "# demonstrate predictions\n",
    "for i in range(X_test.shape[0]):\n",
    "    x_input = X_test[i]\n",
    "    x_input = x_input.reshape((1, n_steps, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    preds.append(yhat[0])\n",
    "    #print(yhat[0], y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After getting the predictions we need to transform the predicted and actual Y values into their original range\n",
    "### Remember we applied scaling previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of the model is between 0 and 1.\n",
    "# Do an inverse map to get it back to the scale\n",
    "# of the original data-set.\n",
    "preds   = x_scaler.inverse_transform(np.array(preds))\n",
    "# we also rescale the y_test values into their original range (inverse scaling)\n",
    "actuals = x_scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(actuals, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot True vs Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple line plot\n",
    "plt.plot(actuals, marker='o', label='True')\n",
    "plt.plot(preds, marker='*', label='Predicted')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple line plot\n",
    "plt.plot(actuals, marker='o', label='True')\n",
    "plt.plot(preds, marker='*', label='Predicted')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WELL DONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
