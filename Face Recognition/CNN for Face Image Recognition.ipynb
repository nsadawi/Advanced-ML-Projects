{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Face Image Recognition\n",
    "\n",
    "This Python code is automatic recognition of the class of a given image\n",
    "\n",
    "In our case, the image will contain the face of some individual\n",
    "\n",
    "\n",
    "## The Data\n",
    "\n",
    "-----------\n",
    "\n",
    "### PLEASE NOTE: THIS DATASET CONTAINS MANY CLASSES .. IT CAN BE DOWNLOADED FROM THE LINK BELOW.\n",
    "### I have downloaded it and manually removed many classes (folders)\n",
    "### I have also added a folder containing my own images\n",
    "--------\n",
    "----------\n",
    "--------\n",
    "ORIGINAL DATA SOURCE:\n",
    "\n",
    "https://cswww.essex.ac.uk/mv/allfaces/faces95.html\n",
    "\n",
    "-----------\n",
    "* The data folders are 'train' and 'test' \n",
    "\n",
    "* Each folder contains subfolders with indiviual names (i.e. persons)\n",
    "\n",
    "* Each indiidual folder contains face images of that individual\n",
    "\n",
    "* The folder name is the person name (it is the class of the image)\n",
    "\n",
    "* The Structure is like this:\n",
    "\n",
    "* Image Data Folder\n",
    "    * Person 1\n",
    "        * 0.jpg\n",
    "        * 1.jpg\n",
    "        * ...\n",
    "    * Person 2\n",
    "        * 0.jpg\n",
    "        * 1.jpg\n",
    "        * ...\n",
    "    * ...\n",
    "    * Person n\n",
    "\n",
    "\n",
    "* The same structure in 'train' and 'test' folders\n",
    "\n",
    "* Train and Test images do not overlap\n",
    "\n",
    "* Only a small number of images to save time .. you can add more on your own time\n",
    "\n",
    "--------\n",
    "----------\n",
    "------------\n",
    "\n",
    "\n",
    "**Note: We will be dealing with real image files, NOT numpy arrays. Which means a large part of this process will be learning how to work with and deal with large groups of image files. This is too much data to fit in memory as a numpy array, so we'll need to feed it into our model in batches. **\n",
    "\n",
    "### Visualizing the Data\n",
    "\n",
    "\n",
    "-------\n",
    "Let's take a closer look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# Technically not necessary in newest versions of jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person1 = cv2.imread('face_images/train/noureddin/noureddin11.jpg')\n",
    "person1 = cv2.cvtColor(person1,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(person1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(person1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person2 = cv2.imread('face_images/test/noureddin/noureddin18.jpg')\n",
    "person2 = cv2.cvtColor(person2,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(person2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for the model\n",
    "\n",
    "Usually your training data contains lots and lots of images .. this is too much data to read all at once in memory. We can use some built in functions in Keras to automatically process the data, generate a flow of batches from a directory, and also manipulate the images.\n",
    "\n",
    "### Image Manipulation\n",
    "\n",
    "Its usually a good idea to manipulate the images with rotation, resizing, and scaling so the model becomes more robust to different images that our data set doesn't have. We can use the **ImageDataGenerator** to do this automatically for us. Check out the documentation for a full list of all the parameters you can use here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rotation_range=20, # rotate the image up to 20 degrees\n",
    "                               width_shift_range=0.1, # Shift the pic width by a max of 10%\n",
    "                               height_shift_range=0.1, # Shift the pic height by a max of 10%\n",
    "                               rescale=1/255, # Rescale the image by normalzing it.\n",
    "                               shear_range=0.2, # Shear means cutting away part of the image (max 20%)\n",
    "                               zoom_range=0.2, # Zoom in by 20% max\n",
    "                               horizontal_flip=True, # Allo horizontal flipping\n",
    "                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_gen.random_transform(person1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_gen.random_transform(person2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating many manipulated images from a directory\n",
    "\n",
    "\n",
    "In order to use .flow_from_directory, you must organize the images in sub-directories (and this is what I have done for you .. this is the recommended way of doing it). This is an absolute requirement, otherwise the method won't work. The directories should only contain images of one class, so one folder per class of images.\n",
    "\n",
    "Structure Needed:\n",
    "\n",
    "* Image Data Folder\n",
    "    * Class 1\n",
    "        * 0.jpg\n",
    "        * 1.jpg\n",
    "        * ...\n",
    "    * Class 2\n",
    "        * 0.jpg\n",
    "        * 1.jpg\n",
    "        * ...\n",
    "    * ...\n",
    "    * Class n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen.flow_from_directory('face_images/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen.flow_from_directory('face_images/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing Images\n",
    "\n",
    "Let's have Keras resize all the images to 200 pixels by 180 pixels once they've been manipulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width,height,channels\n",
    "image_shape = (200,180,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# As we have seen on the slides .. we add Convolutional layers and follow them by Pooling\n",
    "# Notice how we configure the number of filters, filter size etc \n",
    "# There are hyper parameters which we can experiment with!\n",
    "# Check the padding parameter\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=132, kernel_size=(3,3), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# flatten the feature maps to feed into a dense layer as explained on the slides\n",
    "model.add(Flatten())\n",
    "\n",
    "# and here's our dense layer\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Dropouts help reduce overfitting by randomly turning neurons off during training.\n",
    "# Here we say randomly turn off 50% of neurons.\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Last layer, remember its multi-class so we use softmax and categorical_crossentropy\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can experiment with this .. depends on data size etc\n",
    "batch_size = 8\n",
    "\n",
    "train_image_gen = image_gen.flow_from_directory('face_images/train/',\n",
    "                                                #to automatically resize the images\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_gen = image_gen.flow_from_directory('face_images/test/',\n",
    "                                               #to automatically resize the images\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you run this for a large number of epochs it will take a long time\n",
    "### 20 epochs on my laptop take ~27 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = model.fit_generator(train_image_gen,epochs=5,\n",
    "                              #this is useful when you have a large number of images\n",
    "                              steps_per_epoch=150,\n",
    "                              validation_data=test_image_gen,\n",
    "                             validation_steps=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_image_gen.class_indices\n",
    "label_map = train_image_gen.class_indices\n",
    "label_map = dict(map(reversed, label_map.items()))\n",
    "\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_file = 'face_images/test/noureddin/noureddin16.jpg'\n",
    "\n",
    "test_img = image.load_img(test_file, target_size=(200, 180))\n",
    "\n",
    "test_img = image.img_to_array(test_img)\n",
    "\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "test_img = test_img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('face_rec_20epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob = model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output prediction\n",
    "print(f'Probabilities of classes for this image: {prediction_prob} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict(test_img)\n",
    "print(y_prob)\n",
    "label_map[y_prob.argmax(axis=-1)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now let's save the model to use it with our live cam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('face_rec22.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
